tokenizer_list
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "name": "TokenMecab"
    },
    {
      "name": "TokenDelimit"
    },
    {
      "name": "TokenUnigram"
    },
    {
      "name": "TokenBigram"
    },
    {
      "name": "TokenTrigram"
    },
    {
      "name": "TokenBigramSplitSymbol"
    },
    {
      "name": "TokenBigramSplitSymbolAlpha"
    },
    {
      "name": "TokenBigramSplitSymbolAlphaDigit"
    },
    {
      "name": "TokenBigramIgnoreBlank"
    },
    {
      "name": "TokenBigramIgnoreBlankSplitSymbol"
    },
    {
      "name": "TokenBigramIgnoreBlankSplitSymbolAlpha"
    },
    {
      "name": "TokenBigramIgnoreBlankSplitSymbolAlphaDigit"
    },
    {
      "name": "TokenDelimitNull"
    },
    {
      "name": "TokenRegexp"
    },
    {
      "name": "TokenNgram"
    },
    {
      "name": "TokenPattern"
    },
    {
      "name": "TokenTable"
    },
    {
      "name": "TokenDocumentVectorTFIDF"
    },
    {
      "name": "TokenDocumentVectorBM25"
    }
  ]
]
