table_create Lexicon TABLE_PAT_KEY ShortText   --default_tokenizer TokenRegexp   --normalizer NormalizerAuto
[[0,0.0,0.0],true]
table_tokenize Lexicon "abc\nd" --mode ADD
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "￯",
      "position": 0,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "ab",
      "position": 1,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "bc",
      "position": 2,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "c",
      "position": 3,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "d",
      "position": 5,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "￰",
      "position": 6,
      "force_prefix": false,
      "force_prefix_search": false
    }
  ]
]
table_tokenize Lexicon "abc\nd" --mode GET
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "ab",
      "position": 0,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "bc",
      "position": 1,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "d",
      "position": 3,
      "force_prefix": true,
      "force_prefix_search": true
    }
  ]
]
