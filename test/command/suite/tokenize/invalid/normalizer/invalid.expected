tokenize TokenBigram "aBcDe 123" TokenDelimit
[
  [
    [
      -22,
      0.0,
      0.0
    ],
    "[tokenize] failed to set normalizer: <TokenDelimit>: [info][set][normalizers][(anonymous)] invalid normalizers: <TokenDelimit>"
  ]
]
#|e| [info][set][normalizers][(anonymous)] invalid normalizers: <TokenDelimit>
#|e| [tokenize] failed to set normalizer: <TokenDelimit>: [info][set][normalizers][(anonymous)] invalid normalizers: <TokenDelimit>
