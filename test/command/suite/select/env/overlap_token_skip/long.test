#$GRN_II_OVERLAP_TOKEN_SKIP_ENABLE=yes

table_create Entries TABLE_NO_KEY
column_create Entries body COLUMN_SCALAR ShortText

table_create Terms TABLE_PAT_KEY ShortText \
  --default_tokenizer TokenBigramIgnoreBlankSplitSymbolAlpha \
  --normalizer NormalizerAuto

load --table Entries
[
{"body": "This is very very long sentence."}
]

column_create Terms index COLUMN_INDEX|WITH_POSITION Entries body

table_tokenize Terms "This is very very long sentence." --index_column index

log_level --level debug
#@add-important-log-levels debug
#@add-ignore-log-pattern /\A\[io\]/
select Entries --filter 'body @ "This is very very long sentence."'
#@remove-ignore-log-pattern /\A\[io\]/
#@remove-important-log-levels debug
log_level --level notice
