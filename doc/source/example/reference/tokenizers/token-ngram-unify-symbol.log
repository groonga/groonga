Execution example::

  tokenize --tokenizer 'TokenNgram("unify_symbol", false)' --string "___---" --normalizer NormalizerAuto
  #[
  #  [
  #    0,
  #    1558913369.875591,
  #    0.0008268356323242188
  #  ],
  #  [
  #    {
  #      "value": "__",
  #      "position": 0,
  #      "force_prefix": false,
  #      "force_prefix_search": false
  #    },
  #    {
  #      "value": "__",
  #      "position": 1,
  #      "force_prefix": false,
  #      "force_prefix_search": false
  #    },
  #    {
  #      "value": "_-",
  #      "position": 2,
  #      "force_prefix": false,
  #      "force_prefix_search": false
  #    },
  #    {
  #      "value": "--",
  #      "position": 3,
  #      "force_prefix": false,
  #      "force_prefix_search": false
  #    },
  #    {
  #      "value": "--",
  #      "position": 4,
  #      "force_prefix": false,
  #      "force_prefix_search": false
  #    },
  #    {
  #      "value": "-",
  #      "position": 5,
  #      "force_prefix": false,
  #      "force_prefix_search": false
  #    }
  #  ]
  #]
