Execution example::

  tokenize --tokenizer 'TokenNgram("loose_symbol", true, "loose_blank", true)' --string "0123(45)6789" --normalizer NormalizerAuto
  # [
  #   [
  #     0,
  #     1557187317.825164,
  #     0.0003116130828857422
  #   ],
  #   [
  #     {
  #       "value": "0123",
  #       "position": 0,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "(",
  #       "position": 1,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "45",
  #       "position": 2,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": ")",
  #       "position": 3,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "6789",
  #       "position": 4,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "￰",
  #       "position": 5,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "0123456789",
  #       "position": 6,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     }
  #   ]
  # ]
  tokenize --tokenizer 'TokenNgram("loose_symbol", true, "loose_blank", true)' --string "0123-45-6789" --normalizer NormalizerAuto
  # [
  #   [
  #     0,
  #     1557187366.441741,
  #     0.0002820491790771484
  #   ],
  #   [
  #     {
  #       "value": "0123",
  #       "position": 0,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "-",
  #       "position": 1,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "45",
  #       "position": 2,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "-",
  #       "position": 3,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "6789",
  #       "position": 4,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "￰",
  #       "position": 5,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "0123456789",
  #       "position": 6,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     }
  #   ]
  # ]
  tokenize --tokenizer 'TokenNgram("loose_symbol", true, "loose_blank", true)' --string "0123 45 6789" --normalizer NormalizerAuto
  # [
  #   [
  #     0,
  #     1557187404.034283,
  #     0.0003006458282470703
  #   ],
  #   [
  #     {
  #       "value": "0123",
  #       "position": 0,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "45",
  #       "position": 1,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "6789",
  #       "position": 2,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "￰",
  #       "position": 3,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "0123456789",
  #       "position": 4,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     }
  #   ]
  # ]
